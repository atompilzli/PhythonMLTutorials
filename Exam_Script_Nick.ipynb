{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ceb9622",
   "metadata": {},
   "source": [
    "# MLO Practical Exam - Nick Bischofberger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affa62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from numpy import log, exp\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import impute\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, mean_squared_error, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn import decomposition as dcp\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70970d5",
   "metadata": {},
   "source": [
    "### Python navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cdd6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"sex\"]==\"Male\"]\n",
    "df.loc[[5,8]] #df.loc[[observations],[columns]] OR df.loc[5:8,1:4] --> lists inside loc only if you want to access specific columns/observations that are not next to each other\n",
    "df[\"Ticket\"].loc[888]\n",
    "df[df[\"size\"]>=4]\n",
    "df[df[\"Fare\"]==df[\"Fare\"].max()]\n",
    "df.drop(columns=[\"time\"],inplace=True)\n",
    "df.drop(index=892, inplace=True)\n",
    "df.groupby([\"sex\"]).mean()\n",
    "df.groupby([\"size\",\"sex\"]).count()\n",
    "tips.groupby(\"day\").mean()[[\"total_bill\"]]\n",
    "scientists.keys() #Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d1e799",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab308d",
   "metadata": {},
   "source": [
    "#### Loading data and dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f1a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Titanic.csv\")\n",
    "df.drop(columns=[\"time\"],inplace=True)\n",
    "df.drop(index=892, inplace=True)\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93811c2b",
   "metadata": {},
   "source": [
    "#### Check for weird values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530634ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "plt.hist(df['Carat Weight']) #plot histogram to see if values make sense\n",
    "a =~ df[\"Age\"].isna() #finds the locations where Age is *not* empty\n",
    "plt.boxplot(df.loc[a,\"Age\"],vert=False) #filter based on the non-empty values, draw a horizontal boxplot\n",
    "plt.boxplot(df[\"Fare\"],vert=False)\n",
    "plt.hist(df[\"Age\"])\n",
    "plt.scatter(Sarah_raw_data['Carat Weight'],Sarah_raw_data['Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35acbb85",
   "metadata": {},
   "source": [
    "#### Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e649f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Pclass\"].unique()\n",
    "df[\"Name\"].unique().shape\n",
    "\n",
    "df = pd.get_dummies(df,columns=[\"Sex\",\"Embarked\"], drop_first=True) #Binary\n",
    "df[\"Age\"] = df.Age.map({\"Young\":0, \"Mid-aged\":1, \"Old\":2}) #Ordinary, df[\"target column\"] = df.\"base_column\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affe85ba",
   "metadata": {},
   "source": [
    "#### Feautre Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4255718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Fare_euros_2021\"] = df[\"Fare\"]*1.18*118.36\n",
    "df[\"Family_Presence\"]=np.where((df[\"SibSp\"]>=1) | (df[\"Parch\"]>=1), 1,0)\n",
    "df['Carat Weight:Color_E'] = df['Carat Weight'] * df['Color_E']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5df35c",
   "metadata": {},
   "source": [
    "#### Missing values and imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\") #other strategy: \"mean\"\n",
    "df[[\"Embarked\"]]=imp.fit_transform(df[[\"Embarked\"]])\n",
    "imp = KNNImputer(n_neighbors=1)\n",
    "df[[\"Age\"]]=imp.fit_transform(df[[\"Age\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0474bf4",
   "metadata": {},
   "source": [
    "#### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06ac065",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum() #how many duplicates in the dataset\n",
    "df[df.duplicated()] #shows all duplicate rows. Add .count() at the end to see the # of duplicates per column\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff38acb",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4cd443",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df[\"height\"],df[\"weight\"]) #plt.sth[x,y]\n",
    "plt.xlabel(\"height\")\n",
    "plt.ylabel(\"weight\")\n",
    "plt.plot(X,y_pred,color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8936a32a",
   "metadata": {},
   "source": [
    "#### Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a822ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize between 0 and 1 (default)\n",
    "min_max_scaler=preprocessing.MinMaxScaler()\n",
    "X_minmax = min_max_scaler.fit_transform(X)\n",
    "# Scaling (mean = 0, std = 1)\n",
    "X_scaled = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79472e54",
   "metadata": {},
   "source": [
    "## Supervised Learning - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4579624",
   "metadata": {},
   "source": [
    "#### X and Y split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502652a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=\"height\")\n",
    "y = df[[\"weight\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ee11a5",
   "metadata": {},
   "source": [
    "#### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f83f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_other, y_train, y_other= train_test_split(X, y, test_size=0.5) #test_size is for second one\n",
    "X_val, X_test, y_val, y_test= train_test_split(X_other, y_other, test_size=0.5)\n",
    "X_final = pd.concat([X_train, X_val])\n",
    "y_final = pd.concat([y_train, y_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9111ebc2",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f2da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression().fit(X, y)\n",
    "print(\"Intercept = \",lm.intercept_) # Print the resultant model intercept \n",
    "print(\"Model coefficients = \", lm.coef_) # Print the resultant model coefficients (in order of variables in X)\n",
    "print(\"R^2 =\",lm.score(X,y)) # Print the resultant model R-squared\n",
    "\n",
    "y_pred=lm.predict(X)\n",
    "plt.scatter(X,y)\n",
    "plt.plot(X,y_pred,c=\"red\")\n",
    "plt.xlabel(\"height\")\n",
    "plt.ylabel(\"weight\")\n",
    "\n",
    "y_pred = lm.predict(X_val)\n",
    "mean_squared_error(y_val,y_pred, squared=False) #RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d01c6b1",
   "metadata": {},
   "source": [
    "### Polynimoal Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree=3\n",
    "poly = PolynomialFeatures(degree) #define the polynomial\n",
    "X_poly=poly.fit_transform(X) #map all the values of X as [1,x,x^2,x^3, etc]\n",
    "polyreg = LinearRegression().fit(X_poly, y)\n",
    "print(\"Intercept = \",polyreg.intercept_) \n",
    "print(\"Model coefficients = \", polyreg.coef_)\n",
    "print(\"R^2 =\",polyreg.score(X_poly,y))\n",
    "\n",
    "y_pred=polyreg.predict(X_poly) \n",
    "\n",
    "plt.scatter(X,y)\n",
    "linepoints = np.linspace(np.min(X), np.max(X), 100) # create 100 points between 58 and 72\n",
    "linepoints_poly=poly.fit_transform(linepoints) #transform these datapoints into polynomial datapoints\n",
    "linepoints_pred=polyreg.predict(linepoints_poly) #then predict the value we would get on these points with our model\n",
    "plt.plot(linepoints,linepoints_pred)\n",
    "\n",
    "mean_squared_error(y_val,y_pred, squared=False) #RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15477ab",
   "metadata": {},
   "source": [
    "### Log-Log model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad16f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_log=X_train.copy()\n",
    "X_val_log=X_val.copy()\n",
    "y_train_log=y_train.copy()\n",
    "X_train_log[\"Carat Weight\"]=X_train_log[\"Carat Weight\"].apply(log)\n",
    "X_val_log[\"Carat Weight\"]=X_val_log[\"Carat Weight\"].apply(log)\n",
    "y_train_log=y_train_log.apply(log)\n",
    "lm = LinearRegression().fit(X_train_log, y_train_log)\n",
    "print(\"Intercept = \",lm.intercept_) # Print the resultant model intercept \n",
    "print(\"Model coefficients = \", lm.coef_) # Print the resultant model coefficients (in order of variables in X)\n",
    "print(\"R^2 =\",lm.score(X,y)) # Print the resultant model R-squared\n",
    "y_pred_log = lm.predict(X_val_log)\n",
    "mean_squared_error(y_val,np.exp(y_pred_log),squared=False) #RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7be37c",
   "metadata": {},
   "source": [
    "## Supervised learning - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639bc8ab",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c525f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logm = LogisticRegression(max_iter=2000).fit(X_train, y_train) # Fit a logistic regression with vector y as dependent and matrix X as independent\n",
    "print(\"Intercept = \",logm.intercept_) # Print the resultant model intercept \n",
    "print(\"Model coefficients = \", logm.coef_) # Print the resultant model coefficients (in order of variables in X)\n",
    "print(\"R^2 =\",logm.score(X,y)) # Print the resultant model R-squared\n",
    "logm.predict(X_val) #getting the predicted labels\n",
    "y_pred_proba = logm.predict_proba(X_val)[:,1] #getting the predicted probabilities "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882b8fa8",
   "metadata": {},
   "source": [
    "#### Find desired classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a5587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#roccurve[0] = 1-specificity, roccurve[1] = sensitivity, roc curve [2] = evaluated thresholds\n",
    "roccurve=metrics.roc_curve(y_val,y_pred_proba)\n",
    "plt.plot(roccurve[0], roccurve[1], linewidth=4)\n",
    "((roccurve[0]<=0.3) & (roccurve[0]>=0.2)) & (roccurve[1]>=0.9) #Pick your favorite threshold \n",
    "roccurve[1][((roccurve[0]<=0.3) & (roccurve[0]>=0.2)) & (roccurve[1]>=0.9)] #sensitivity\n",
    "roccurve[2][((roccurve[0]<=0.3) & (roccurve[0]>=0.2)) & (roccurve[1]>=0.9)] #thresholds\n",
    "roccurve[0][((roccurve[0]<=0.3) & (roccurve[0]>=0.2)) & (roccurve[1]>=0.9)] #1-specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d30ee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = pd.concat([X_train,X_val])\n",
    "y_final = pd.concat([y_train, y_val])\n",
    "\n",
    "logm = LogisticRegression().fit(X_final, y_final)\n",
    "y_pred_proba = logm.predict_proba(X_test)[:,1] #predictions of the probabilities on the test data\n",
    "threshold = 0.018 #desired threshold\n",
    "y_pred = np.where(y_pred_proba > threshold, 1, 0) # predicted label based on defined threshold\n",
    "\n",
    "confusion_matrix(y_test,y_pred)\n",
    "accuracy_score(y_test,y_pred)\n",
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd3a78",
   "metadata": {},
   "source": [
    "### Trees (Decision Tree, RandomForest and GradientBoosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f72a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_DT = DecisionTreeClassifier(max_leaf_nodes = 6)\n",
    "# classifier_RF = RandomForestClassifier(max_leaf_nodes = 13)\n",
    "# classifier_GBM = GradientBoostingClassifier(max_leaf_nodes = 13)\n",
    "classifier_DT.fit(X_train, y_train) # change model to _RF or _GBM\n",
    "y_pred_prob=classifier_DT.predict_proba(X_val)[:,1] # change model to _RF or _GBM\n",
    "print(roc_auc_score(y_val, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032eb964",
   "metadata": {},
   "source": [
    "#### Plot tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054bf9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10,8)) #makes plot large\n",
    "tree.plot_tree(classifier_DT,  class_names=(\"Died\",\"Survived\"), feature_names=X_train.columns, filled=True) # change model to _RF or _GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7511e1cb",
   "metadata": {},
   "source": [
    "#### Find best number of leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8a7c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_leaf_nodes = range(2,60) # Lets train the models with 2, 3, 4, ... 60 leafs\n",
    "array_train = []\n",
    "array_val= []\n",
    "for n in n_max_leaf_nodes:\n",
    "    classifier_DT = DecisionTreeClassifier(max_leaf_nodes = n).fit(X_train, y_train)\n",
    "    #classifier_DT = RandomForestClassifier(max_leaf_nodes = n).fit(X_train, y_train)\n",
    "    #classifier_DT = GradientBoostingClassifier(max_leaf_nodes = n).fit(X_train, y_train)\n",
    "    y_pred_train = classifier_DT.predict_proba(X_train)[:,1] # change model to _RF or _GBM\n",
    "    y_pred_val = classifier_DT.predict_proba(X_val)[:,1] # change model to _RF or _GBM\n",
    "    score_train=roc_auc_score(y_train,y_pred_train)\n",
    "    score_val=roc_auc_score(y_val,y_pred_val)\n",
    "    array_train.append(score_train)\n",
    "    array_val.append(score_val)\n",
    "\n",
    "plt.scatter(n_max_leaf_nodes,array_train)\n",
    "plt.scatter(n_max_leaf_nodes,array_val)\n",
    "plt.legend(['Training set','Validation set'])\n",
    "plt.xlabel(\"Number of leaves\",fontsize=15)\n",
    "plt.ylabel(\"AUC\",fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aa3419",
   "metadata": {},
   "source": [
    "#### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_DT = DecisionTreeClassifier(max_leaf_nodes = 10) #optimal # of leaf nodes\n",
    "#classifier_RF = RandomForestClassifier(max_leaf_nodes = 15) #optimal # of leaf nodes\n",
    "#classifier_GBM = GradientBoostingClassifier(max_leaf_nodes = 15) #optimal # of leaf nodes\n",
    "\n",
    "X_final = pd.concat([X_train,X_val])\n",
    "y_final = pd.concat([y_train, y_val])\n",
    "\n",
    "classifier_DT.fit(X_final, y_final) # change model to _RF or _GBM\n",
    "y_pred = classifier_DT.predict(X_test) # change model to _RF or _GBM\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd880df5",
   "metadata": {},
   "source": [
    "#### Change the classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22076b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_DT = DecisionTreeClassifier(max_leaf_nodes = 10) #optimal # of leaf nodes\n",
    "#classifier_RF = RandomForestClassifier(max_leaf_nodes = 15) #optimal # of leaf nodes\n",
    "#classifier_GBM = GradientBoostingClassifier(max_leaf_nodes = 15) #optimal # of leaf nodes\n",
    "classifier_DT.fit(X_final, y_final)\n",
    "y_pred_prob=classifier_DT.predict_proba(X_test)[:,1] #different from \n",
    "threshold=0.7\n",
    "y_pred=np.where(y_pred_prob>threshold,1,0)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085967cf",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e346856",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(classifier_DT.feature_importances_, index=X_final.columns) # change model to _RF or _GBM\n",
    "feat_importances.nlargest(5).plot(kind='barh') #select # features to show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23966798",
   "metadata": {},
   "source": [
    "## Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a27d30",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cov()\n",
    "df[\"Age\"].var()/df.var().sum() # divide variance of every column by total variance to get relative variance\n",
    "\n",
    "df=pd.DataFrame()\n",
    "#creating centered variables\n",
    "Vit_C_centered=menu[\"Vitamin C\"]-menu[\"Vitamin C\"].mean()\n",
    "Total_Fat_centered=menu[\"Total Fat\"]-menu[\"Total Fat\"].mean()\n",
    "Cholesterol_centered=menu[\"Cholesterol\"]-menu[\"Cholesterol\"].mean()\n",
    "df[\"z1\"]=-0.17718634*Vit_C_centered+0.54454878*Total_Fat_centered+0.81979975*Cholesterol_centered\n",
    "df[\"z2\"]=0.98405437*Vit_C_centered+0.08485918*Total_Fat_centered+0.15631992*Cholesterol_centered\n",
    "df[\"z3\"]=0.01555629*Vit_C_centered+0.83442528*Total_Fat_centered-0.5509149*Cholesterol_centered\n",
    "\n",
    "pca=dcp.PCA(n_components=3) # change to desired number of principal components\n",
    "pca.fit(df)\n",
    "loadings = pca.components_ #loadings\n",
    "pca.explained_variance_ #variance\n",
    "rel_var = pca.explained_variance_ratio_ #relative variance\n",
    "data_pca = pca.fit_transform(df) #scores\n",
    "pd.DataFrame(data=[loadings[0], loadings[1]], index=[\"z1\",\"z2\"],columns=menu_num.columns) #adjust loadings [0] and z1,z2,... to number of principal components\n",
    "cumsum = np.cumsum(rel_var)\n",
    "plt.title(\"Explained Variance Ratio by Component\")\n",
    "plt.plot(range(1,11),cumsum) # change to desired number of principal components\n",
    "plt.xlabel(\"Component\")\n",
    "plt.ylabel(\"Variance Ratio\")\n",
    "plt.show()\n",
    "index = np.where(cumsum>=0.95) # first number in array that is returned is the number of prinipal components to keep to get 95% explained variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadde31e",
   "metadata": {},
   "source": [
    "### KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83344202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing.scale(df) # scale before KMeans\n",
    "kmeans = KMeans(n_clusters=4).fit(df) #specify number of desired clusters\n",
    "labels = kmeans.labels_ #clusters, clusters start from 0\n",
    "df[\"Cluster\"] = labels # add labels to dataframe\n",
    "kmeans.cluster_centers_ #optimized centers = centroids\n",
    "print(df[df[\"Cluster\"]==1].shape) #How many are in cluster 1\n",
    "df[df[\"Cluster\"]==1].mean().sort_values().tail() #Gives you the mean for each column in cluster 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1541eac8",
   "metadata": {},
   "source": [
    "#### Find optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ffc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question, this is to select the right K, right?\n",
    "inertia_K=[] #sum of all distances from centroid to points squared, we want low inertia\n",
    "K = range(1,10) #select range of clusters you want\n",
    "for k in K:\n",
    "    kmeans =KMeans(n_clusters=k).fit(df)\n",
    "    inertia_K.append(kmeans.inertia_)\n",
    "plt.plot(K,inertia_K) #Question: Can we not replace range with K?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d730db",
   "metadata": {},
   "source": [
    "### Hierarchial Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9aa0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing.scale(df) # scale before Hierarch. Clustering\n",
    "Z = linkage(df,method='average') #other methods: \"average\",\"single\", \"complete\", \"ward\"\n",
    "dendrogram(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fbd774",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = fcluster(Z, 3, criterion='maxclust') #The # is the number of clusters?\n",
    "df[\"Cluster\"] = labels #add labels to dataframe\n",
    "print(df[df[\"Cluster\"]==1].shape) #How many are in cluster 1\n",
    "df[df[\"Cluster\"]==1].mean().sort_values().tail() #Gives you the mean for each column in cluster 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62153902",
   "metadata": {},
   "source": [
    "#### Visualize average scores for cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans\n",
    "df_pca_km= df_pca.copy() #df_pca = scores\n",
    "df_pca_km[\"Labels\"] = labels #use the labels obtained\n",
    "df_pca_km_clust=df_pca_km.groupby(df_pca_km[\"Labels\"]).mean().reset_index() #take the average over the 5 new features based on the clusters\n",
    "df_pca_km_clust=df_pca_km_clust.drop(columns=[\"Labels\"]).set_index(np.arange(1,6)) #obtain a dataframe that contains this information\n",
    "\n",
    "sns.heatmap(df_pca_km_clust,cmap=\"PiYG\") #plot a heatmap of this\n",
    "plt.xlabel('Average score for each feature', fontsize = 15) # x-axis label with fontsize 15\n",
    "plt.ylabel('Cluster', fontsize = 15) # y-axis label with fontsize 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c4e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical clustering\n",
    "df_pca_hier = df_pca.copy()\n",
    "df_pca_hier[\"Labels\"]=labels # hierarchical_clustering\n",
    "df_pca_hier_clust = df_pca_hier.groupby(df_pca_hier[\"Labels\"]).mean().reset_index()\n",
    "df_pca_hier_clust=df_pca_hier_clust.drop(columns=[\"Labels\"]).set_index(np.arange(1,6))\n",
    "\n",
    "sns.heatmap(df_pca_hier_clust,cmap=\"PiYG\")\n",
    "plt.xlabel('Average score for each feature', fontsize = 15) # x-axis label with fontsize 15\n",
    "plt.ylabel('Cluster', fontsize = 15) # y-axis label with fontsize 15"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
